{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729dbb3a-77ce-4eb6-bd8e-5626640e0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "from attackcti import attack_client\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667bbd0-e468-49aa-8483-2bbce3855c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the attack_client object\n",
    "client = attack_client()\n",
    "\n",
    "# Get all techniques\n",
    "techniques = client.get_enterprise_techniques()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa87918-1bc5-49a4-b645-32ef1041586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries containing the technique ID, name, and description\n",
    "technique_list = []\n",
    "for technique in techniques:\n",
    "    technique_dict = {\n",
    "        'ID': technique['external_references'][0]['external_id'],\n",
    "        'Name': technique['name'],\n",
    "        'Description': technique['description']\n",
    "    }\n",
    "    technique_list.append(technique_dict)\n",
    "\n",
    "# Create a pandas DataFrame from the list of dictionaries\n",
    "mitre_df = pd.DataFrame(technique_list)\n",
    "\n",
    "print(mitre_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c87109b7-3b3e-4ada-a8db-de0ff9ab539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the rule from a given line\n",
    "def parse_rule(rule_line):\n",
    "    rule_dict = {}\n",
    "    # Define pattern for the outer part of the rule (e.g., \"alert tcp $HOME_NET any -> $EXTERNAL_NET any\")\n",
    "    outer_pattern = r\"(?P<action>\\w+) (?P<protocol>\\w+) (?P<src>\\$[A-Z_]+ [a-z]*) -> (?P<dst>\\$[A-Z_]+ [a-z]*)\"\n",
    "    # Attempt to match the outer pattern\n",
    "    outer_match = re.match(outer_pattern, rule_line)\n",
    "    if outer_match:\n",
    "        # If outer part is matched, add it to the rule dictionary\n",
    "        rule_dict.update(outer_match.groupdict())\n",
    "        # Define pattern for the inner part of the rule (e.g., \"(msg:\"RULE_MSG\"; sid:1000006; rev:001;)\")\n",
    "        inner_pattern = r\"\\((?P<inner_contents>.*)\\)\"\n",
    "        # Attempt to match the inner pattern\n",
    "        inner_match = re.search(inner_pattern, rule_line)\n",
    "        if inner_match:\n",
    "            # If inner part is matched, further process it\n",
    "            inner_contents = inner_match.group(\"inner_contents\").split(\";\")\n",
    "            for content in inner_contents:\n",
    "                content = content.strip()\n",
    "                if \":\" in content:\n",
    "                    # Split each content on \":\" to get key-value pairs and add them to the rule dictionary\n",
    "                    key, value = content.split(\":\", 1)\n",
    "                    rule_dict[key.strip()] = value.strip('\" ')\n",
    "    return rule_dict\n",
    "\n",
    "# Define the folder where the rules are stored\n",
    "folder_path = 'D:/python/snort mitre/rules'  \n",
    "# Prepare a list to store all parsed rules\n",
    "all_rules = []\n",
    "\n",
    "# Loop over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Create the full file path by joining the folder path and the filename\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        # Loop over each line in the file\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # Only process lines that start with 'alert' (i.e., are rule lines)\n",
    "            if line.startswith('alert'):  \n",
    "                # Parse the rule and add it to the list\n",
    "                rule_dict = parse_rule(line)\n",
    "                all_rules.append(rule_dict)\n",
    "\n",
    "# Download the stopwords from NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Define additional stopwords specific to the cybersecurity context\n",
    "cyber_stop_words = {'attempt', 'other', 'known', 'org','user'}\n",
    "# Update the list of stopwords\n",
    "stop_words.update(cyber_stop_words)\n",
    "\n",
    "# Prepare a dictionary to count the frequency of each term\n",
    "# Use a defaultdict to avoid KeyErrors and automatically initialize missing keys to 0\n",
    "term_frequencies = defaultdict(int)\n",
    "# Define the fields where keywords should be extracted from\n",
    "keyword_fields = ['msg']\n",
    "\n",
    "# Loop over each parsed rule\n",
    "for rule in all_rules:\n",
    "    # Loop over each keyword field\n",
    "    for field in keyword_fields:\n",
    "        # If the field is present in the rule\n",
    "        if field in rule:\n",
    "            # Use NLTK's word_tokenize function to tokenize the field's value\n",
    "            tokens = word_tokenize(rule[field])\n",
    "            # Loop over each token\n",
    "            for token in tokens:\n",
    "                # Ignore tokens that are either too short or are stop words\n",
    "                if len(token) > 2 and token not in stop_words:\n",
    "                    # Increment the term's count\n",
    "                    term_frequencies[token] += 1\n",
    "\n",
    "# Find the 20 most common terms and their frequencies\n",
    "most_common_terms = sorted(term_frequencies.items(), key=lambda x: x[1], reverse=True)\n",
    "# Print the most common terms and their frequencies\n",
    "ordered_keywords = []\n",
    "for term, freq in most_common_terms:\n",
    "    ordered_keywords.append(term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5afc983a-2392-433b-8229-aae5d2cb1f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3474"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ordered_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ec95aa8-cee0-4dc2-9329-07234b46571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing the MITRE techniques\n",
    "mitre_df['tokenized_desc'] = mitre_df['Description'].apply(word_tokenize)\n",
    "mitre_df['tokenized_desc'] = mitre_df['tokenized_desc'].apply(lambda x: [word for word in x if word not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1bee933-5477-4779-b962-7363a91b7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial preparation\n",
    "lut = []\n",
    "keyword_counts = {}  # Dictionary to keep track of total keyword counts across all techniques\n",
    "\n",
    "for keyword in ordered_keywords:\n",
    "    # Find techniques that mention the keyword in their description\n",
    "    relevant_techniques = mitre_df[mitre_df['tokenized_desc'].apply(lambda desc: keyword in desc)].copy()\n",
    "\n",
    "    if not relevant_techniques.empty:\n",
    "        # Count how many times the keyword appears in each description\n",
    "        relevant_techniques['keyword_count'] = relevant_techniques['tokenized_desc'].apply(lambda desc: desc.count(keyword))\n",
    "        # Add the total count to the keyword_counts dictionary\n",
    "        keyword_counts[keyword] = relevant_techniques['keyword_count'].sum()\n",
    "        # Sort techniques by how often they mention the keyword\n",
    "        relevant_techniques = relevant_techniques.sort_values('keyword_count', ascending=False)\n",
    "\n",
    "        # Prepare LUT entry\n",
    "        lut_entry = {'keyword': keyword}\n",
    "\n",
    "        # Prepare list to store notes about non-top techniques\n",
    "        non_top_techniques = []\n",
    "\n",
    "        for i, (index, row) in enumerate(relevant_techniques.iterrows()):\n",
    "            technique = row['Name']\n",
    "            keyword_count = row['keyword_count']\n",
    "\n",
    "            # Compute confidence score as the ratio of keyword_count for the technique \n",
    "            # to the total count of the keyword in all descriptions, round to 2 decimal places\n",
    "            confidence = round(keyword_count / keyword_counts[keyword], 2)\n",
    "\n",
    "            if i < 2:\n",
    "                # Top techniques\n",
    "                lut_entry[f'tech_{i+1}'] = technique\n",
    "                lut_entry[f'tech_{i+1}_confidence'] = confidence\n",
    "            else:\n",
    "                # Non-top techniques, store for notes\n",
    "                non_top_techniques.append(f'{technique} (confidence: {confidence})')\n",
    "\n",
    "        # Convert list of non-top techniques into a single string and add it to the LUT entry\n",
    "        lut_entry['notes'] = '; '.join(non_top_techniques)\n",
    "\n",
    "        lut.append(lut_entry)\n",
    "\n",
    "    # Stop when the LUT has 200 entries\n",
    "    if len(lut) >= 200:\n",
    "        break\n",
    "\n",
    "# Convert the LUT to a DataFrame\n",
    "lut_df = pd.DataFrame(lut)\n",
    "lut_df.to_csv('keyword_MITRE_LUT.csv', index=False)\n",
    "lut_df.to_excel('keyword_MITRE_LUT.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32e7c3-1b86-4447-9d71-8169da477ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3929f82-ad05-427f-b045-ee363e96ac6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
